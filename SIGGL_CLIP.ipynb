{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JMQ6IUhSP0-4",
        "outputId": "113bcef4-204b-4bfa-ce7d-71e8d0b7617c"
      },
      "outputs": [],
      "source": [
        "!pip install ftfy regex tqdm\n",
        "!pip install git+https://github.com/openai/CLIP.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ZP-ItqDP4wm",
        "outputId": "cd6e8545-20c8-495f-91ad-5a29a4db7fe7"
      },
      "outputs": [],
      "source": [
        "#download and extract im2gps\n",
        "!wget http://www.cis.jhu.edu/~shraman/im2gps_rgb_images.tar.gz\n",
        "!tar -xzvf \"/content/im2gps_rgb_images.tar.gz\" -C \"/content/\"     #[run this cell to extract tar.gz files]\n",
        "!wget http://www.cis.jhu.edu/~shraman/im2gps3k_rgb_images.tar.gz\n",
        "!tar -xzvf \"/content/im2gps3k_rgb_images.tar.gz\" -C \"/content/\"     #[run this cell to extract tar.gz files]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 748
        },
        "id": "xx3FUOS87jJX",
        "outputId": "fc9896de-4d11-4dfd-ce55-b171baa97d6b"
      },
      "outputs": [],
      "source": [
        "#Generate continental labels from lattitude and longitude values\n",
        "!pip install pycountry_convert\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from geopy.geocoders import Nominatim\n",
        "from geopy.extra.rate_limiter import RateLimiter\n",
        "import pycountry_convert as pc\n",
        "\n",
        "from pprint import pprint\n",
        "from typing import Tuple\n",
        "\n",
        "from tqdm import tqdm\n",
        "tqdm.pandas()\n",
        "\n",
        "\n",
        "\n",
        "def get_continent_name(continent_code: str) -> str:\n",
        "    continent_dict = {\n",
        "        \"NA\": \"North America\",\n",
        "        \"SA\": \"South America\",\n",
        "        \"AS\": \"Asia\",\n",
        "        \"AF\": \"Africa\",\n",
        "        \"OC\": \"Oceania\",\n",
        "        \"EU\": \"Europe\",\n",
        "        \"AQ\" : \"Antarctica\"\n",
        "    }\n",
        "    return continent_dict[continent_code]\n",
        "\n",
        "def get_continent(lat: float, lon:float) -> Tuple[str, str]:\n",
        "    geolocator = Nominatim(user_agent=\"<username1>@gmail.com\", timeout=10)\n",
        "    # geocode = RateLimiter(geolocator.reverse, min_delay_seconds=.01)\n",
        "    geocode = RateLimiter(geolocator.reverse)\n",
        "\n",
        "    location = geocode(f\"{lat}, {lon}\", language=\"en\")\n",
        "\n",
        "    # for cases where the location is not found, coordinates are antarctica\n",
        "    if location is None:\n",
        "        return \"Antarctica\", \"Antarctica\"\n",
        "\n",
        "    # extract country code\n",
        "    address = location.raw[\"address\"]\n",
        "    country_code = address[\"country_code\"].upper()\n",
        "\n",
        "    # get continent code from country code\n",
        "    continent_code = pc.country_alpha2_to_continent_code(country_code)\n",
        "    continent_name = get_continent_name(continent_code)\n",
        "    \n",
        "    return country_code, continent_name\n",
        "\n",
        "#labels files can be found here: https://github.com/ShramanPramanick/Transformer_Based_Geo-localization/tree/main/resources\n",
        "im2gpslabels3k = pd.read_csv('im2gps3k_places365.csv')\n",
        "im2gpslabels = pd.read_csv('im2gps_places365.csv')\n",
        "\n",
        "\n",
        "im2gpslabels3k[[\"COUNTRY\", \"CONTINENT\"]] = im2gpslabels3k.progress_apply(\n",
        "    lambda x: get_continent(x[\"LAT\"], x[\"LON\"]), axis=1, result_type=\"expand\")\n",
        "\n",
        "im2gpslabels[[\"COUNTRY\", \"CONTINENT\"]] = im2gpslabels.progress_apply(\n",
        "    lambda x: get_continent(x[\"LAT\"], x[\"LON\"]), axis=1, result_type=\"expand\")\n",
        "\n",
        "\n",
        "im2gpslabels3k.to_csv(\"im2gpslabels3k.csv\")\n",
        "im2gpslabels.to_csv(\"im2gpslabels.csv\") "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iAJenmEPQiAs"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import clip\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "import os\n",
        "import pandas as pd\n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MKjpRr8aQTTO",
        "outputId": "73542c90-6b0f-438c-b175-1c683c680f48"
      },
      "outputs": [],
      "source": [
        "\n",
        "#BATCH_SIZE must larger than 1\n",
        "\n",
        "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\" # If using GPU then use mixed precision training.\n",
        "model, preprocess = clip.load(\"ViT-B/32\",device=device,jit=False) #Must set jit=False for training\n",
        "\n",
        "batch_size = 128\n",
        "\n",
        "class image_title_dataset(Dataset):\n",
        "    def __init__(self, list_image_path,list_txt):\n",
        "\n",
        "        self.image_path = list_image_path\n",
        "        self.title  = clip.tokenize(list_txt) #you can tokenize everything at once in here(slow at the beginning), or tokenize it in the training loop.\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.title)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image = preprocess(Image.open(self.image_path[idx])) # Image from PIL module\n",
        "        title = self.title[idx]\n",
        "        return image,title\n",
        "\n",
        "# use your own data\n",
        "\n",
        "test_labels = pd.read_csv(\"im2gpslabels.csv\")[[\"IMG_ID\", \"CONTINENT\"]]\n",
        "#test_dataset = CustomImageDataset(\"im2gpslabels.csv\", \"/content/im2gps_rgb_images/\")\n",
        "train_labels = pd.read_csv(\"im2gps3klabels.csv\")[[\"IMG_ID\", \"CONTINENT\"]]\n",
        "#train_dataset = CustomImageDataset(\"im2gps3klabels.csv\", \"/content/im2gps3k_rgb_images/\")\n",
        "\n",
        "train_img_path = \"/content/im2gps3k_rgb_images/\"\n",
        "train_list_image_path = [train_img_path + img_name for img_name in train_labels[\"IMG_ID\"]]\n",
        "train_list_txt = [label for label in train_labels[\"CONTINENT\"]]\n",
        "\n",
        "train_dataset = image_title_dataset(train_list_image_path,train_list_txt)\n",
        "train_dataloader = DataLoader(train_dataset, batch_size = batch_size) #Define your own dataloader\n",
        "\n",
        "test_img_path = \"/content/im2gps_rgb_images/\"\n",
        "test_list_image_path = [test_img_path + img_name for img_name in test_labels[\"IMG_ID\"]]\n",
        "test_list_txt = [label for label in test_labels[\"CONTINENT\"]]\n",
        "\n",
        "test_dataset = image_title_dataset(test_list_image_path,test_list_txt)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size = batch_size) #Define your own dataloader\n",
        "\n",
        "#https://github.com/openai/CLIP/issues/57\n",
        "def convert_models_to_fp32(model): \n",
        "    for p in model.parameters(): \n",
        "        p.data = p.data.float() \n",
        "        p.grad.data = p.grad.data.float() \n",
        "\n",
        "\n",
        "if device == \"cpu\":\n",
        "  model.float()\n",
        "else :\n",
        "  clip.model.convert_weights(model) # Actually this line is unnecessary since clip by default already on float16\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "id": "v0Ufx_2PQkG-",
        "outputId": "95e00340-3d1b-47bd-f294-27fca5b9d28b"
      },
      "outputs": [],
      "source": [
        "loss_img = nn.CrossEntropyLoss()\n",
        "loss_txt = nn.CrossEntropyLoss()\n",
        "optimizer = optim.AdamW(model.parameters(), lr=5e-6,betas=(0.9,0.98),eps=1e-6,weight_decay=0.2) #Params used from paper, the lr is smaller, more safe for fine tuning to new dataset\n",
        "\n",
        "epochs = 10\n",
        "\n",
        "# add your own code to track the training progress.\n",
        "for epoch in range(epochs):\n",
        "  for batch in train_dataloader :\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      images,texts = batch \n",
        "    \n",
        "      images= images.to(device)\n",
        "      texts = texts.to(device)\n",
        "    \n",
        "      logits_per_image, logits_per_text = model(images, texts)\n",
        "\n",
        "      ground_truth = torch.arange(len(images),dtype=torch.long,device=device)\n",
        "\n",
        "      total_loss = (loss_img(logits_per_image,ground_truth) + loss_txt(logits_per_text,ground_truth))/2\n",
        "      total_loss.backward()\n",
        "      if device == \"cpu\":\n",
        "         optimizer.step()\n",
        "      else : \n",
        "        convert_models_to_fp32(model)\n",
        "        optimizer.step()\n",
        "        clip.model.convert_weights(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aEoLlKiJqrK9"
      },
      "outputs": [],
      "source": [
        "torch.save({\n",
        "        'epoch': epochs,\n",
        "        'model_state_dict': model.state_dict(),\n",
        "        'optimizer_state_dict': optimizer.state_dict(),\n",
        "        'loss': total_loss,\n",
        "        }, f\"model_1000.pt\") #just change to your preferred folder/filename"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Oe598pnNY_X_"
      },
      "outputs": [],
      "source": [
        "#Evaluate Accuracy\n",
        "correct = 0\n",
        "total = 0\n",
        "eval_model = model.eval()\n",
        "\n",
        "all_labels = [\"Africa\", \"Asia\", \"Europe\", \"North America\", \"South America\", \"Oceania\"]\n",
        "continent_dict = {'Africa': 0, 'Asia': 1, \"Europe\": 2, \"North America\": 3, \"South America\": 4, \"Oceania\":5, 0:'Africa', 1:\"Asia\", 2:\"Europe\", 3:\"North America\", 4:\"South America\", 5: \"Oceania\"}\n",
        "\n",
        "text_inputs = torch.cat([clip.tokenize(f\"{c}\") for c in all_labels]).to(device)\n",
        "with torch.no_grad():\n",
        "  text_features = eval_model.encode_text(text_inputs)\n",
        "  text_features /= text_features.norm(dim=-1, keepdim=True)\n",
        "\n",
        "for i in range(len(test_list_image_path)):\n",
        "  print(i)\n",
        "  image = Image.open(test_list_image_path[i])\n",
        "  class_id = continent_dict[test_labels[\"CONTINENT\"][i]]\n",
        "\n",
        "  image_input = preprocess(image).unsqueeze(0).to(device)\n",
        "\n",
        "  # Calculate features\n",
        "  with torch.no_grad():\n",
        "      image_features = eval_model.encode_image(image_input)\n",
        "\n",
        "  image_features /= image_features.norm(dim=-1, keepdim=True)\n",
        "  similarity = (100.0 * image_features @ text_features.T).softmax(dim=-1)\n",
        "  values, indices = similarity[0].topk(6)\n",
        "  \n",
        "  if indices[0] == class_id:\n",
        "    correct += 1\n",
        "    print(\"correct\")\n",
        "  \n",
        "  total +=1\n",
        "\n",
        "  print(values)\n",
        "  print(indices)\n",
        "  # Print the result\n",
        "  print(\"\\nTop predictions:\\n\")\n",
        "  print(\"Correct: \", test_labels[\"CONTINENT\"][i])\n",
        "  for value, index in zip(values, indices):\n",
        "      print(f\"{all_labels[index]:>16s}: {100 * value.item():.2f}%\")\n",
        "\n",
        "print(\"Accuracy: \", correct/total)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QX4trzIm2SG8"
      },
      "outputs": [],
      "source": [
        "#training set stats\n",
        "import matplotlib.pyplot as plt\n",
        "count = train_labels[\"CONTINENT\"].value_counts()\n",
        "count.plot.bar()\n",
        "plt.ylabel('Number of records')\n",
        "plt.xlabel('Target Class')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dr1FlrI2XalU"
      },
      "outputs": [],
      "source": [
        "#Test set stats\n",
        "import matplotlib.pyplot as plt\n",
        "count = test_labels[\"CONTINENT\"].value_counts()\n",
        "count.plot.bar()\n",
        "plt.ylabel('Number of records')\n",
        "plt.xlabel('Target Class')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mhkgrcKiYwVp"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
